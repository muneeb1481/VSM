the effect dataset size training tweet sentiment classifier sentiment analysis tweet mining classification big data using automated method labeling tweet sentiment large volume tweet labeled used train classifier million tweet could used train classifier however doing so computationally expensive thus it valuable establish how many tweet should utilized train classifier since using additional instance with gain performance waste resource this study seek find out how many tweet needed before significant improvement observed sentiment analysis when adding additional instance train evaluate classifier using decision tree na ve bayes nearest neighbor radial basis function network with seven datasets varying from instance model trained using four run fold cross validation additionally conduct statistical test verify our observation examine impact limiting feature using frequency learner were found improve with dataset size with na ve bayes being best performing learner found that na ve bayes did not significantly benefit from using more than instance best our knowledge this first study investigate how learner scale respect dataset size with result verified using statistical test multiple model trained each learner dataset size additionally investigated using feature frequency greatly reduce data grid size with either small increase or decrease classifier performance depending choice learner